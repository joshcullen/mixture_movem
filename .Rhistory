z=sample.z(nobs=nobs,nmaxclust=nmaxclust,dat=dat,ltheta=ltheta,lphi=lphi,ndata.types=ndata.types)
for (j in 1:ndata.types){
nmat[[j]]=SummarizeDat(z=z-1, dat=dat[,j]-1, ncateg=ncat.dat[j],nbehav=nmaxclust, nobs=nobs)
}
tmp=sample.v(z=z,gamma1=gamma1,nmaxclust=nmaxclust)
theta=tmp$theta
v=tmp$v
phi=sample.phi(alpha=alpha,nmaxclust=nmaxclust,
ncat.dat=ncat.dat,ndata.types=ndata.types,nmat=nmat)
gamma1=sample.gamma(v=v,ngroup=nmaxclust,gamma.possib=gamma.possib)
#calculate log-likelihood
llk=get.llk(phi=phi,theta=theta,ndata.types=ndata.types,dat=dat,
nobs=nobs,nmaxclust=nmaxclust)
#store results
# for (j in 1:ndata.types){
#   store.phi[[j]][i,]=phi[[j]]
# }
# store.theta[i,]=theta
store.loglikel[i]=llk
store.gamma1[i]=gamma1
#re-order clusters
if (i < nburn & i%%50==0){
ordem=order(theta,decreasing=T)
theta=theta[ordem]
for (j in 1:ndata.types){
phi[[j]]=phi[[j]][ordem,]
nmat[[j]]=nmat[[j]][ordem,]
}
znew=z
for (j in 1:nmaxclust){
cond=z==ordem[j]
znew[cond]=j
}
z=znew
}
max.llk=llk
theta.max.llk=theta
names(theta.max.llk)<- 1:length(theta.max.llk)
ord<- theta.max.llk %>% sort(decreasing = T) %>% names()
phi.max.llk=phi
View(phi.max.llk)
phi.max.llk
phi.max.llk=t(phi)
phi.max.llk
phi.max.llk=phi
phi.max.llk<- lapply(phi.max.llk, t)
phi.max.llk
phi.max.llk<- lapply(phi.max.llk, function(x) x[,as.numeric(ord)])
phi.max.llk
z.max.llk=z
z.max.llk
z.max.llk<- factor(z.max.llk)
z.max.llk
levels(z.max.llk)<- ord
z.max.llk<- as.numeric(z.max.llk)
z.max.llk
z.max.llk=z
class(z.max.llk)
replace(z.max.llk, 1:length(z.max.llk), ord)
z.max.llk=z
z.max.llk<- factor(z.max.llk)
z.max.llk
levels(z.max.llk)
levels(z.max.llk)<- ord
levels(z.max.llk)
z.max.llk
z.max.llk=z
z.max.llk<- factor(z.max.llk)
z.max.llk
levels(z.max.llk)<- ord
z.max.llk
z.max.llk<- as.numeric(z.max.llk)
z.max.llk
z.max.llk=z
z.max.llk<- factor(z.max.llk)
levels(z.max.llk)<- ord
z.max.llk<- as.numeric(as.character(z.max.llk))
z.max.llk
mixture_movement=function(dat,alpha,ngibbs,nmaxclust,nburn){
nobs=nrow(dat)
ndata.types=ncol(dat)
#initial values
z=sample(1:nmaxclust,size=nobs,replace=T)
ncat.dat=apply(dat,2,max,na.rm=T)
phi=list()
for (i in 1:ndata.types){
phi[[i]]=matrix(1/ncat.dat[i],nmaxclust,ncat.dat[i])
}
theta=rep(1/nmaxclust,nmaxclust)
gamma1=0.1
#get nmat
nmat=list()
for (i in 1:ndata.types){
nmat[[i]]=SummarizeDat(z=z-1, dat=dat[,i]-1, ncateg=ncat.dat[i],nbehav=nmaxclust, nobs=nobs)
}
#prepare for gibbs
store.phi=list()
for (i in 1:ndata.types){
# store.phi[[i]]=matrix(NA,ngibbs,nmaxclust*ncat.dat[i])
}
# store.theta=matrix(NA,ngibbs,nmaxclust)
store.loglikel=rep(NA,ngibbs)
store.gamma1=rep(NA,ngibbs)
#run gibbs sampler
max.llk=-Inf
gamma.possib=seq(from=0.1,to=1,by=0.05) #possible values for gamma
#progress bar
pb <- progress::progress_bar$new(
format = " iteration (:current/:total) [:bar] :percent [Elapsed: :elapsed, Remaining: :eta]",
total = ngibbs, clear = FALSE, width = 100)
for (i in 1:ngibbs){
pb$tick()  #create progress bar
#sample from FCD's
lphi=list()
for (j in 1:ndata.types) lphi[[j]]=log(phi[[j]])
ltheta=log(theta)
z=sample.z(nobs=nobs,nmaxclust=nmaxclust,dat=dat,ltheta=ltheta,lphi=lphi,ndata.types=ndata.types)
for (j in 1:ndata.types){
nmat[[j]]=SummarizeDat(z=z-1, dat=dat[,j]-1, ncateg=ncat.dat[j],nbehav=nmaxclust, nobs=nobs)
}
tmp=sample.v(z=z,gamma1=gamma1,nmaxclust=nmaxclust)
theta=tmp$theta
v=tmp$v
phi=sample.phi(alpha=alpha,nmaxclust=nmaxclust,
ncat.dat=ncat.dat,ndata.types=ndata.types,nmat=nmat)
gamma1=sample.gamma(v=v,ngroup=nmaxclust,gamma.possib=gamma.possib)
#calculate log-likelihood
llk=get.llk(phi=phi,theta=theta,ndata.types=ndata.types,dat=dat,
nobs=nobs,nmaxclust=nmaxclust)
#store results
# for (j in 1:ndata.types){
#   store.phi[[j]][i,]=phi[[j]]
# }
# store.theta[i,]=theta
store.loglikel[i]=llk
store.gamma1[i]=gamma1
#re-order clusters
if (i < nburn & i%%50==0){
ordem=order(theta,decreasing=T)
theta=theta[ordem]
for (j in 1:ndata.types){
phi[[j]]=phi[[j]][ordem,]
nmat[[j]]=nmat[[j]][ordem,]
}
znew=z
for (j in 1:nmaxclust){
cond=z==ordem[j]
znew[cond]=j
}
z=znew
}
}
if (i > nburn & llk>max.llk){
max.llk=llk
theta.max.llk=theta
names(theta.max.llk)<- 1:length(theta.max.llk)
ord<- theta.max.llk %>% sort(decreasing = T) %>% names()
phi.max.llk=phi
phi.max.llk<- lapply(phi.max.llk, t)
phi.max.llk<- lapply(phi.max.llk, function(x) x[,as.numeric(ord)])
z.max.llk=z
z.max.llk<- factor(z.max.llk)
levels(z.max.llk)<- ord
z.max.llk<- as.numeric(as.character(z.max.llk))
}
# list(phi=store.phi,theta=store.theta,
#      loglikel=store.loglikel,z=z.max.llk,
#      gamma1=store.gamma1)
list(phi=phi.max.llk,theta=theta.max.llk,
loglikel=store.loglikel,z=z.max.llk,
gamma1=store.gamma1)
}
# future::plan(future::multisession)  #run all MCMC chains in parallel
# dat.res<- segment_behavior(data = tracks.list2, ngibbs = ngibbs, nbins = nbins,
#                            alpha = alpha)
model1=mixture_movement(dat=tracks[,-1],alpha=alpha,ngibbs=ngibbs,nmaxclust=nmaxclust,nburn=nburn)
plot(model1$loglikel, type = "l")
plot(model1$gamma1, type = "l")
View(model1)
class(model1$theta)
model1$theta
mixture_movement=function(dat,alpha,ngibbs,nmaxclust,nburn){
nobs=nrow(dat)
ndata.types=ncol(dat)
#initial values
z=sample(1:nmaxclust,size=nobs,replace=T)
ncat.dat=apply(dat,2,max,na.rm=T)
phi=list()
for (i in 1:ndata.types){
phi[[i]]=matrix(1/ncat.dat[i],nmaxclust,ncat.dat[i])
}
theta=rep(1/nmaxclust,nmaxclust)
gamma1=0.1
#get nmat
nmat=list()
for (i in 1:ndata.types){
nmat[[i]]=SummarizeDat(z=z-1, dat=dat[,i]-1, ncateg=ncat.dat[i],nbehav=nmaxclust, nobs=nobs)
}
#prepare for gibbs
store.phi=list()
for (i in 1:ndata.types){
# store.phi[[i]]=matrix(NA,ngibbs,nmaxclust*ncat.dat[i])
}
# store.theta=matrix(NA,ngibbs,nmaxclust)
store.loglikel=rep(NA,ngibbs)
store.gamma1=rep(NA,ngibbs)
#run gibbs sampler
max.llk=-Inf
gamma.possib=seq(from=0.1,to=1,by=0.05) #possible values for gamma
#progress bar
pb <- progress::progress_bar$new(
format = " iteration (:current/:total) [:bar] :percent [Elapsed: :elapsed, Remaining: :eta]",
total = ngibbs, clear = FALSE, width = 100)
for (i in 1:ngibbs){
pb$tick()  #create progress bar
#sample from FCD's
lphi=list()
for (j in 1:ndata.types) lphi[[j]]=log(phi[[j]])
ltheta=log(theta)
z=sample.z(nobs=nobs,nmaxclust=nmaxclust,dat=dat,ltheta=ltheta,lphi=lphi,ndata.types=ndata.types)
for (j in 1:ndata.types){
nmat[[j]]=SummarizeDat(z=z-1, dat=dat[,j]-1, ncateg=ncat.dat[j],nbehav=nmaxclust, nobs=nobs)
}
tmp=sample.v(z=z,gamma1=gamma1,nmaxclust=nmaxclust)
theta=tmp$theta
v=tmp$v
phi=sample.phi(alpha=alpha,nmaxclust=nmaxclust,
ncat.dat=ncat.dat,ndata.types=ndata.types,nmat=nmat)
gamma1=sample.gamma(v=v,ngroup=nmaxclust,gamma.possib=gamma.possib)
#calculate log-likelihood
llk=get.llk(phi=phi,theta=theta,ndata.types=ndata.types,dat=dat,
nobs=nobs,nmaxclust=nmaxclust)
#store results
# for (j in 1:ndata.types){
#   store.phi[[j]][i,]=phi[[j]]
# }
# store.theta[i,]=theta
store.loglikel[i]=llk
store.gamma1[i]=gamma1
#re-order clusters
if (i < nburn & i%%50==0){
ordem=order(theta,decreasing=T)
theta=theta[ordem]
for (j in 1:ndata.types){
phi[[j]]=phi[[j]][ordem,]
nmat[[j]]=nmat[[j]][ordem,]
}
znew=z
for (j in 1:nmaxclust){
cond=z==ordem[j]
znew[cond]=j
}
z=znew
}
}
if (i > nburn & llk>max.llk){
max.llk=llk
theta.max.llk=theta
names(theta.max.llk)<- 1:length(theta.max.llk)
theta.max.llk<- theta.max.llk %>% sort(decreasing = T)
ord<- names(theta.max.llk)
phi.max.llk=phi
phi.max.llk<- lapply(phi.max.llk, t)
phi.max.llk<- lapply(phi.max.llk, function(x) x[,as.numeric(ord)])
z.max.llk=z
z.max.llk<- factor(z.max.llk)
levels(z.max.llk)<- ord
z.max.llk<- as.numeric(as.character(z.max.llk))
}
# list(phi=store.phi,theta=store.theta,
#      loglikel=store.loglikel,z=z.max.llk,
#      gamma1=store.gamma1)
list(phi=phi.max.llk,theta=theta.max.llk,
loglikel=store.loglikel,z=z.max.llk,
gamma1=store.gamma1)
}
# future::plan(future::multisession)  #run all MCMC chains in parallel
# dat.res<- segment_behavior(data = tracks.list2, ngibbs = ngibbs, nbins = nbins,
#                            alpha = alpha)
model1=mixture_movement(dat=tracks[,-1],alpha=alpha,ngibbs=ngibbs,nmaxclust=nmaxclust,nburn=nburn)
plot(model1$loglikel, type = "l")
plot(model1$gamma1, type = "l")
View(model1)
model1$theta
model1$phi
colSums(model1$phi[[1]])
colSums(model1$phi[[2]])
library(bayesmove)
data("tracks.list")
#subset only first track
tracks.list<- dplyr::bind_rows(tracks.list)
#only retain id and discretized step length (SL) and turning angle (TA) columns
tracks<- subset(tracks.list, select = c(id, SL, TA))
set.seed(1)
# Define model params
alpha=0.1
ngibbs=1000
nburn=ngibbs/2
nmaxclust=7
# future::plan(future::multisession)  #run all MCMC chains in parallel
# dat.res<- segment_behavior(data = tracks.list2, ngibbs = ngibbs, nbins = nbins,
#                            alpha = alpha)
model1=mixture_movement(dat=tracks[,-1],alpha=alpha,ngibbs=ngibbs,nmaxclust=nmaxclust,nburn=nburn)
source('mixmov_function.R')
source('mixmov_gibbs.R')
sourceCpp('aux1.cpp')
# rm(list=ls(all=TRUE))
library('MCMCpack')
library('Rcpp')
source('mixmov_function.R')
source('mixmov_gibbs.R')
sourceCpp('aux1.cpp')
set.seed(1)
# Define model params
alpha=0.1
ngibbs=1000
nburn=ngibbs/2
nmaxclust=7
# future::plan(future::multisession)  #run all MCMC chains in parallel
# dat.res<- segment_behavior(data = tracks.list2, ngibbs = ngibbs, nbins = nbins,
#                            alpha = alpha)
model1=mixture_movement(dat=tracks[,-1],alpha=alpha,ngibbs=ngibbs,nmaxclust=nmaxclust,nburn=nburn)
plot(model1$loglikel, type = "l")
plot(model1$gamma1, type = "l")
theta<- model1$theta
theta
theta %>% cumsum()
behav.res<- get_behav_hist(dat = model1, nburn = nburn, ngibbs = ngibbs, nmaxclust = nmaxclust,
var.names = c("Step Length","Turning Angle"))
# Plot histograms of proportion data
ggplot(behav.res, aes(x = bin, y = prop, fill = as.factor(behav))) +
geom_bar(stat = 'identity') +
labs(x = "\nBin", y = "Proportion\n") +
theme_bw() +
theme(axis.title = element_text(size = 16),
axis.text.y = element_text(size = 14),
axis.text.x.bottom = element_text(size = 12),
strip.text = element_text(size = 14),
strip.text.x = element_text(face = "bold")) +
scale_fill_manual(values = c(viridis::viridis(5),
"grey35","grey35"), guide = FALSE) +
scale_y_continuous(breaks = c(0.00, 0.50, 1.00)) +
scale_x_continuous(breaks = 1:8) +
facet_grid(behav ~ var, scales = "free_x")
# Plot histograms of proportion data
lilibrary(ggplot2)
# Plot histograms of proportion data
library(ggplot2)
ggplot(behav.res, aes(x = bin, y = prop, fill = as.factor(behav))) +
geom_bar(stat = 'identity') +
labs(x = "\nBin", y = "Proportion\n") +
theme_bw() +
theme(axis.title = element_text(size = 16),
axis.text.y = element_text(size = 14),
axis.text.x.bottom = element_text(size = 12),
strip.text = element_text(size = 14),
strip.text.x = element_text(face = "bold")) +
scale_fill_manual(values = c(viridis::viridis(5),
"grey35","grey35"), guide = FALSE) +
scale_y_continuous(breaks = c(0.00, 0.50, 1.00)) +
scale_x_continuous(breaks = 1:8) +
facet_grid(behav ~ var, scales = "free_x")
library(bayesmove)
data("tracks.list")
#subset only first track
tracks.list<- dplyr::bind_rows(tracks.list)
#only retain id and discretized step length (SL) and turning angle (TA) columns
tracks<- subset(tracks.list, select = c(id, SL, TA))
set.seed(1)
# Define model params
alpha=0.1
ngibbs=1000
nburn=ngibbs/2
nmaxclust=7
# future::plan(future::multisession)  #run all MCMC chains in parallel
# dat.res<- segment_behavior(data = tracks.list2, ngibbs = ngibbs, nbins = nbins,
#                            alpha = alpha)
model1=mixture_movement(dat=tracks[,-1],alpha=alpha,ngibbs=ngibbs,nmaxclust=nmaxclust,nburn=nburn)
# rm(list=ls(all=TRUE))
library('MCMCpack')
library('Rcpp')
source('mixmov_function.R')
source('mixmov_gibbs.R')
sourceCpp('aux1.cpp')
set.seed(1)
# Define model params
alpha=0.1
ngibbs=1000
nburn=ngibbs/2
nmaxclust=7
# future::plan(future::multisession)  #run all MCMC chains in parallel
# dat.res<- segment_behavior(data = tracks.list2, ngibbs = ngibbs, nbins = nbins,
#                            alpha = alpha)
model1=mixture_movement(dat=tracks[,-1],alpha=alpha,ngibbs=ngibbs,nmaxclust=nmaxclust,nburn=nburn)
plot(model1$loglikel, type = "l")
plot(model1$gamma1, type = "l")
View(model1)
MAP.iter<- get_MAP(dat = model1, nburn = nburn)
get_MAP
MAP.iter<- get_MAP(dat = model1$theta, nburn = nburn)
bayesmove::get_MAP_internal
bayesmove::::get_MAP_internal
bayesmove:::get_MAP_internal
MAP.iter<- get_MAP(dat = model1$loglikel, nburn = nburn)
MAP.iter<- bayesmove:::get_MAP_internal(dat = model1$loglikel, nburn = nburn)
MAP.est<- model1$loglikel[-1] %>%
order(decreasing = T)
which.max(model1$loglikel[-1])
theta<- model1$theta[MAP.iter,]
theta %>% cumsum()
theta
names(theta)
names(theta)<- 1:ncol(theta)
1:length(theta)
names(theta)<- 1:length(theta)
theta<- sort(theta, decreasing = TRUE)
theta
theta %>% cumsum()
ord<- as.numeric(names(theta))
get_behav_hist1=function(dat, nburn, ngibbs, nmaxclust, var.names, ord, MAP.iter) {
#summarize cluster results by frequency and proportion
behav.list<- list()
for (i in 1:length(dat$phi)) {
if ("z" %in% names(dat)) {  #for mixture model
tmp<- matrix(dat$phi[[i]][MAP.iter,], 1, ncol(dat$phi[[i]]))
tmp1<- matrix(tmp, ncol(tmp) / nmaxclust, nmaxclust, byrow = T)
tmp1<- tmp1[,as.numeric(ord)]
} else {  #for LDA
tmp<- matrix(dat$phi[[i]][(nburn+1):ngibbs,], length((nburn+1):ngibbs),
ncol(dat$phi[[i]]))
tmp1<- matrix(colMeans(tmp), ncol(tmp) / nmaxclust, nmaxclust, byrow = T)
}
behav.list[[i]]<- data.frame(bin = 1:nrow(tmp1), tmp1) %>%
dplyr::rename_at(dplyr::vars(tidyr::starts_with('X')), ~as.character(1:ncol(tmp1))) %>%
tidyr::pivot_longer(-.data$bin, names_to = "behav", values_to = "prop") %>%
dplyr::arrange(.data$behav) %>%
dplyr::mutate(var = var.names[i])
}
#combine params
behav.res<- dplyr::bind_rows(behav.list)
behav.res
}
behav.res<- get_behav_hist1(dat = model1, nburn = nburn, ngibbs = ngibbs, nmaxclust = nmaxclust,
var.names = c("Step Length","Turning Angle"), ord = ord,
MAP.iter = MAP.iter)
View(behav.res)
# Plot histograms of proportion data
library(ggplot2)
ggplot(behav.res, aes(x = bin, y = prop, fill = as.factor(behav))) +
geom_bar(stat = 'identity') +
labs(x = "\nBin", y = "Proportion\n") +
theme_bw() +
theme(axis.title = element_text(size = 16),
axis.text.y = element_text(size = 14),
axis.text.x.bottom = element_text(size = 12),
strip.text = element_text(size = 14),
strip.text.x = element_text(face = "bold")) +
scale_fill_manual(values = c(viridis::viridis(5),
"grey35","grey35"), guide = FALSE) +
scale_y_continuous(breaks = c(0.00, 0.50, 1.00)) +
scale_x_continuous(breaks = 1:8) +
facet_grid(behav ~ var, scales = "free_x")
View(tracks)
tracks<- tracks[,-c("id")]
tracks<- tracks[,-"id"]
ind<- which(names(tracks) == "id")
ind<- which(colnames(tracks) == "id")
View(model1)
View(model1)
library(bayesmove)
data(tracks.list)
#subset only first track
tracks.list<- dplyr::bind_rows(tracks.list)
#only retain id and discretized step length (SL) and turning angle (TA) columns
tracks<- subset(tracks.list, select = c(id, SL, TA))
set.seed(1)
# Define model params
alpha=0.1
ngibbs=1000
nburn=ngibbs/2
nmaxclust=7
model1=cluster_obs(dat=tracks, alpha=alpha, ngibbs=ngibbs, nmaxclust=nmaxclust, nburn=nburn)
plot(model1$loglikel, type = "l")
plot(model1$gamma1, type = "l")
MAP.iter<- bayesmove:::get_MAP_internal(dat = model1$loglikel, nburn = nburn)
theta<- model1$theta[MAP.iter,]
names(theta)<- 1:length(theta)
theta<- sort(theta, decreasing = TRUE)
theta %>% cumsum()  #first 5 states optimal (i.e. > 90%)
ord<- as.numeric(names(theta))
behav.res<- get_behav_hist1(dat = model1, nburn = nburn, ngibbs = ngibbs, nmaxclust = nmaxclust,
var.names = c("Step Length","Turning Angle"), ord = ord,
MAP.iter = MAP.iter)
behav.res<- get_behav_hist(dat = model1, nburn = nburn, ngibbs = ngibbs, nmaxclust = nmaxclust,
var.names = c("Step Length","Turning Angle"), ord = ord,
MAP.iter = MAP.iter)
library(ggplot2)
ggplot(behav.res, aes(x = bin, y = prop, fill = as.factor(behav))) +
geom_bar(stat = 'identity') +
labs(x = "\nBin", y = "Proportion\n") +
theme_bw() +
theme(axis.title = element_text(size = 16),
axis.text.y = element_text(size = 14),
axis.text.x.bottom = element_text(size = 12),
strip.text = element_text(size = 14),
strip.text.x = element_text(face = "bold")) +
scale_fill_manual(values = c(viridis::viridis(5),
"grey35","grey35"), guide = FALSE) +
scale_y_continuous(breaks = c(0.00, 0.50, 1.00)) +
scale_x_continuous(breaks = 1:8) +
facet_grid(behav ~ var, scales = "free_x")
future:::ClusterRegistry("stop")
